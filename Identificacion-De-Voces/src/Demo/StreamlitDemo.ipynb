{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPP0bzOOfBkk5rEIFhwt6aL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install streamlit -q"],"metadata":{"id":"tOsSLHttvmVJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install autogluon.tabular==1.1.1 -q"],"metadata":{"id":"1Z9luYMOvwcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q -O - ipv4.icanhazip.com"],"metadata":{"id":"7U29WZZIwD5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7E02pypjzut4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVxh2M1ptvFr"},"outputs":[],"source":["%%writefile app.py\n","import streamlit as st\n","import librosa\n","import numpy as np\n","from sklearn.svm import SVC\n","from autogluon.tabular import TabularPredictor\n","import pandas as pd\n","import pickle as pkl\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","\n","\n","path_Autogluon = \"/content/drive/My Drive/ProyectoTesis/Autogluon/Modelos2\"\n","path_LSTM = \"/content/drive/My Drive/ProyectoTesis/LSTM/LRModelHistories.pkl\"\n","path_svm_kernels = \"/content/drive/My Drive/ProyectoTesis/SVM/Streamlit/\"\n","path_scaler = \"/content/drive/My Drive/ProyectoTesis/Scaler.pkl\"\n","\n","with open(path_scaler, 'rb') as file:\n","  scaler = pkl.load(file)\n","\n","# PATH=\"Models/Autogluon/\"\n","# Dummy models (replace with pre-trained models or train new ones)\n","def predict(model_name, features):\n","\n","  with open(path_scaler, 'rb') as file:\n","    scaler = pkl.load(file)\n","\n","  if model_name == \"SVM\":\n","\n","    models_svm = []\n","    import os\n","    for file_name in os.listdir(path_svm_kernels):\n","      path = os.path.join(path_svm_kernels, file_name)\n","      with open(path, 'rb') as file:\n","        models_svm.append((file_name[:-4], pkl.load(file)))\n","\n","    features, columns = features\n","    data = [[np.mean(features[i]) for i in range(len(features))]]\n","    data = scaler.transform(data)\n","\n","    results = {}\n","\n","    for name, mod in models_svm:\n","      results[name] = \"Bonafide\" if mod.predict(data)[0] == 0 else \"Spoof\"\n","\n","    st.write(results)\n","\n","    pass\n","  elif model_name == \"Autogluon\":\n","    features, columns = features\n","    data = [[np.mean(features[i]) for i in range(len(features))]]\n","    data = scaler.transform(data)\n","    data = pd.DataFrame(data, columns=columns)\n","\n","    predictor = TabularPredictor.load(path_Autogluon)\n","    autogluon_models = predictor.model_names()[:-1]\n","    results = {}\n","\n","    for model in autogluon_models:\n","      prediction = predictor.predict(data, model=model)[0]\n","      prediction = \"Bonafide\" if prediction == 0 else \"Spoof\"\n","      results[model] = prediction\n","\n","    st.write(results)\n","\n","\n","  #LSTM\n","  else:\n","    with open(path_LSTM, 'rb') as file:\n","      models = pkl.load(file)\n","\n","    features, columns = features\n","    st.write(len(features))\n","    features = np.array(features)\n","    new_features = np.transpose(features, (1,0))\n","\n","    scaled_features = np.array([scaler.transform(new_features)])\n","    new_features = np.array([new_features])\n","    #st.write(scaled_features)\n","    results = {}\n","\n","    for mod in models:\n","      hist, mod, lr, ttime = mod\n","      pred = mod.predict(new_features)\n","      results[lr] = pred\n","    st.write(results)\n","\n","def specificModel():\n","  predictor = TabularPredictor.load(path_Autogluon)\n","  autogluon_models = predictor.model_names()[:-1]\n","  svm_models = ['SVM_POLYNOMIAL', 'SVM_RBF', 'SVM_SIGMOID']\n","  svm_models.extend([f'SVM_RADIAL_C_{10**i}' for i in range(-1, 3)])\n","  lrs = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n","  lstm_models = [f\"LSTM_LR_{lrs[i]}\" for i in range(len(lrs))]\n","  models = autogluon_models + svm_models + lstm_models\n","\n","# Feature extraction\n","def extract_features(audio):\n","    y, sr =  librosa.load(audio)\n","    sr = 16000\n","    features = {\n","        'zcr': librosa.feature.zero_crossing_rate(y)[0],\n","        'rmse': librosa.feature.rms(y=y)[0],\n","        'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr)[0],\n","        'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr)[0],\n","        'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr)[0],\n","        'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr)[0],\n","        'chroma_stft': librosa.feature.chroma_stft(y=y, sr=sr)[0],\n","    }\n","    # Add all 13 MFCCs\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=10)\n","\n","    for i in range(10):\n","        features[f'mfcc{i+1}'] = mfccs[i]\n","\n","    ret_value = [val for val in features.values()]\n","    return ret_value, features.keys()\n","\n","# App\n","st.title(\"Audio Feature Extraction and Prediction\")\n","\n","# Upload audio file\n","uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"wav\", \"mp3\", \"flac\"])\n","\n","if uploaded_file is not None:\n","    # Save uploaded file temporarily\n","    with open(\"temp_audio_file.wav\", \"wb\") as f:\n","        f.write(uploaded_file.read())\n","\n","    # Extract features\n","    st.write(\"Extracting features...\")\n","    features = extract_features(\"temp_audio_file.wav\")\n","    st.write(f\"Extracted features: {len(features[0])}\")\n","\n","    # Model selection\n","    st.write(\"Select a Machine Learning Model:\")\n","    models = ['SVM', 'Autogluon', 'LSTM']\n","    model_name = st.selectbox(\"Choose a model\", models)\n","\n","    # Train model with dummy data (replace this with actual training and models)\n","    if st.button(\"Predict\"):\n","      predict(model_name, features)\n"]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501"],"metadata":{"id":"WIuyHY-dwTyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xfSELfVywcvO"},"execution_count":null,"outputs":[]}]}